{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO8njh9MEASLQtwWXgHNhXC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/codml/AI_jupyter/blob/main/SpyTorch_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4Fq90OuUPSA9",
        "outputId": "781ec90e-216f-417e-ce91-518919ea19a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "import seaborn as sns\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# The coarse network structure is dicated by the Fashion MNIST dataset.\n",
        "nb_inputs = 28*28\n",
        "nb_hidden = 100\n",
        "nb_outputs = 10\n",
        "\n",
        "time_step = 1e-3\n",
        "nb_steps = 100\n",
        "\n",
        "batch_size = 256\n",
        "\n",
        "dtype = torch.float\n",
        "\n",
        "# Check whether a GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Here we load the Dataset\n",
        "root = os.path.expanduser(\"~/data/datasets/torch/fashion-mnist\")\n",
        "train_dataset = torchvision.datasets.FashionMNIST(root, train=True, transform=None, target_transform=None, download=True)\n",
        "test_dataset = torchvision.datasets.FashionMNIST(root, train=False, transform=None, target_transform=None, download=True)\n",
        "\n",
        "# Standardize data\n",
        "# x_train = torch.tensor(train_dataset.train_data, device=device, dtype=dtype)\n",
        "x_train = np.array(train_dataset.data, dtype=np.float)\n",
        "x_train = x_train.reshape(x_train.shape[0],-1)/255\n",
        "# x_test = torch.tensor(test_dataset.test_data, device=device, dtype=dtype)\n",
        "x_test = np.array(test_dataset.data, dtype=np.float)\n",
        "x_test = x_test.reshape(x_test.shape[0], -1)/255\n",
        "\n",
        "# y_train = torch.tensor(train_dataset.train_labels, device=device, dtype=dtype)\n",
        "# y_test = torch.tensor(test_dataset.test_labels, device=device, dtype=dtype)\n",
        "y_train = np.array(train_dataset.targets, dtype=np.int)\n",
        "y_test = np.array(test_dataset.targets, dtype=np.int)\n",
        "\n",
        "# Here we plot one of the raw data points as an example\n",
        "data_id = 1\n",
        "plt.imshow(x_train[data_id].reshape(28,28), cmap=plt.cm.gray_r)\n",
        "plt.axis(\"off\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VZRNhvQ4RpYo",
        "outputId": "de6e8ad6-e38d-46af-c286-cb08371ed0c5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12220528.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw/train-images-idx3-ubyte.gz to /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 205001.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw/train-labels-idx1-ubyte.gz to /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3866829.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 5982897.48it/s]\n",
            "<ipython-input-3-062a45ee1435>:26: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x_train = np.array(train_dataset.data, dtype=np.float)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to /root/data/datasets/torch/fashion-mnist/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-062a45ee1435>:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  x_test = np.array(test_dataset.data, dtype=np.float)\n",
            "<ipython-input-3-062a45ee1435>:34: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_train = np.array(train_dataset.targets, dtype=np.int)\n",
            "<ipython-input-3-062a45ee1435>:35: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  y_test = np.array(test_dataset.targets, dtype=np.int)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(-0.5, 27.5, 27.5, -0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAANSklEQVR4nO3cv6vW9f/H8df55dHyxykzMrShUAhrsMFC2hpca2ksaGpoC1r6CwJbWuIDjRE4RENLNES01JCGlChYEFGKg6ahHjs/v8MXHsvnw5fP88nXy6vj7bY/uK5znet09z30nNnc3NwcADDGmL3XbwCA6SEKAIQoABCiAECIAgAhCgCEKAAQogBAzN/rN/BP0/l//WZmZu7CO7m3zp8/X9689dZbrdd69dVXy5ujR4+WN9u2bStv5ufrf0Lnzp0rb8YY47PPPitvnnzyyfLmnXfeKW+WlpbKG6aTJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAmNnsXHibQlvtUN0PP/zQ2p06daq8+fTTT8ububm58ubmzZvlzRhjLC8vlzfXrl1rvdY0O3z4cHkzO1v/d9+FCxfKm8cee6y8OXHiRHkzxhhvv/12efPss8+2Xut+5EkBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAILbMQbxJ+euvv8qb1157rbw5e/ZseTNG7zDgzp07y5sdO3aUN/Pz8+XNGL3je2tra+XNjRs3ypsHHnigvOn8PGNM9wHHO3fulDedQ4djjLGyslLevPjii+XNxx9/XN5sBZ4UAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhXUoteeuml8ua3334rb/bu3VvejNG7pLm+vl7edC99TsrGxkZ5s7CwUN50Pruurfan2v15Ot/xy5cvlzdffPFFefP000+XN9PGkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAzN/rN3AvnT59urzpHLd75JFHypu1tbXypmt5ebm8+eOPPybyOmP0jtvNz9e/2p3jdrOzk/t31crKSnnTOfK3a9eu8ubAgQPlTed31NX5PX300Uflzfvvv1/eTBtPCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAxs7m5uXmv38S9cvLkyfLmgw8+KG/27t1b3nQPrXWOx3Ve68033yxv9u/fX96MMcbBgwfLm0uXLpU3nffX+bw7R+rG6B3Eu3nzZnlz5syZ8qbzd7Fv377yZowxVldXy5u//vqrvOkcSPz111/Lm2njSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAg7uuDeC+88EJ5c+XKlfJm9+7d5c22bdvKmzF6B9D27NlT3nz33XflzZdfflnejDHG77//Xt688cYb5c2//vWv8ubIkSPlzZ07d8qbMXoH2h599NHy5ujRo+XNoUOHypudO3eWN2P0Pr/OEcILFy6UNz/99FN5M8YYhw8fbu3uBk8KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCADF/r9/AvXT27Nny5uDBg+VN55DZ33//Xd503bhxYyKvc+LEidauczjt/Pnz5c3JkyfLm1deeaW8+fzzz8ubMcZYW1srbzrH7c6cOVPezM/X/1Ny+/bt8maMMWZn6/+W7Ww6f+vffvtteTOGg3gATClRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAIgtcyX1xx9/LG/27dtX3szNzZU3nSupnc0YYywvL5c3Dz/8cOu1qs6dO9faLS4uljeXL18ub959993yZnNzs7xZWFgob7qv1b3aWbV///7y5tKlS63X6vwNzszMlDc7duwob7755pvyZowxXn/99dbubvCkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABBb5iDee++9V950jsc9+OCD5c38fP1jvn37dnkzxhjbt28vbzoH2r7//vvy5urVq+XNGGNcu3atvFldXS1vrly5Ut50PrvO72iMMVZWVsqb69evlzenTp0qb/7888/ypnNwbozez9R5rc536PTp0+XNtPGkAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABBb5iDe8ePHy5vOAbSff/65vLlx40Z50z2Id+jQofJmdrb+b4Pnn3++vJmbmytvxui9v85mY2OjvOkcTdvc3CxvxugdVlxfXy9vdu/eXd4cPny4vLl161Z5M0bv99T5zB9//PHy5uWXXy5vpo0nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYCY2exe57pP/fnnn+XNxYsXy5sPP/ywvBljjK+//rq8eeKJJ8qbzpG/paWl8maMMVZWVsqbztG0adf5U+18Dtu3by9vOt+HZ555prwZY4xPPvmkteO/40kBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgJi/12/gn+ahhx4qb44dO1beLC4uljdjjPHVV1+VNzMzM+XN33//Xd7cunWrvBljjLW1tfJmdnYy/97pXC7tHibu/Eyd39PCwkJ5c+fOnfLm+PHj5Q13nycFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgLivD+J1DpOtrq6WN9u2bStvOkfqxhhj165d5c36+np5Mzc3V950f6aOzu92ku9vmm1sbEzkdZaWlibyOmP0vuOdA4Rb4TvkSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAg7uuDeJ3jVQsLC3fhnfy7p556qrXbvXt3ebO2tlbedI78dXV+Tw7i/a/O72llZeUuvJN/t2fPnom8zhi9I3+do49bgScFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgLivD+J1TOqw1o4dO8qbMcZYXFwsb+7cuVPedA4Drq6uljdjTO64Xed1OpvOd6hr+/bt5c3t27fLm87ncL8enJt2nhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwkG8os6htY7Z2V6vO7vOzzSpg3Ndnfc3qUN13c9hUp9f5zu0vr4+kdfpmtTf7VbgSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAcCV1i7l06VJ5s7S0VN50rmJ2da6DTvIi6zTrfA4LCwsTeZ21tbXyhrvPkwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAOIhXNDMzc6/fwv9pbm5uIq+zsrJS3szO9v4NMqmDeJ1N5/vQPdbXea3O72lxcbG86by3SR7Em/a/22niSQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgHMTbYjrHzDY2NsqbzuG9zuuM0TukN6kDbQsLC+VN9zjb+vr6RF5rfn4y/1m4fv36RF6HGk8KAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCAOEg3hbTOVQ3KZubm61d94BcVefg3KSOx43R+xw6n3nndTqHAZeXl8ubrkl9h7YCTwoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA4SDeFtM56jYp036UrHuwb1I6n9/GxsZEXqdziPH27dvlDXefJwUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwpXUomm/9NnRuaQ57SZ18XSSV2k7373O59D5PszP1/9TMs0Xfe9nnhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAwkG8os6BsUke0du2bVt5s7y8fBfeyf+f2dn6v106R93m5uYm8jqdn6drUkf0Op/dtB8TvF95UgAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIB/GY2PG4zqG1MXrvb1KbznG77ufQ0TkE1/kcOiZ5EI//nicFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgHAQr6hzYGySHn/88fLm4sWL5c38fP2r0zke192trKxM5HU634fud6jzma+urrZeaxImeRBv2v9up4knBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCldQt5vr16+XNzZs3y5vO9c2rV6+WN2P0rmlubGyUN9N8UXSM3pXUzmd34MCB8mZ5ebm8+eWXX8qbrs73oXvV95/u/vypAfiPRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIB/GKNjc3y5uZmZm78E7+s+eee668OXLkSHmztLRU3kzy4FznANrOnTvLm87vtvMdGqN3EK9z1G1hYaG86RxiPHbsWHnTdb8et+vwSQEQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgDEzGb3OhcAW44nBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAOJ/ABtRtiWstPxEAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def current2firing_time(x, tau=20, thr=0.2, tmax=1.0, epsilon=1e-7):\n",
        "    \"\"\" Computes first firing time latency for a current input x assuming the charge time of a current based LIF neuron.\n",
        "\n",
        "    Args:\n",
        "    x -- The \"current\" values\n",
        "\n",
        "    Keyword args:\n",
        "    tau -- The membrane time constant of the LIF neuron to be charged\n",
        "    thr -- The firing threshold value\n",
        "    tmax -- The maximum time returned\n",
        "    epsilon -- A generic (small) epsilon > 0\n",
        "\n",
        "    Returns:\n",
        "    Time to first spike for each \"current\" x\n",
        "    \"\"\"\n",
        "    idx = x<thr\n",
        "    x = np.clip(x,thr+epsilon,1e9)\n",
        "    T = tau*np.log(x/(x-thr))\n",
        "    T[idx] = tmax\n",
        "    return T\n",
        "\n",
        "def sparse_data_generator(X, y, batch_size, nb_steps, nb_units, shuffle=True):\n",
        "    \"\"\" This generator takes datasets in analog format and generates spiking network input as sparse tensors.\n",
        "\n",
        "    Args:\n",
        "        X: The data ( sample x event x 2 ) the last dim holds (time, neuron) tuples\n",
        "        y: The labels\n",
        "    \"\"\"\n",
        "\n",
        "    labels_ = np.array(y, dtype=np.int)\n",
        "    number_of_batches = len(X)//batch_size\n",
        "    sample_index = np.arange(len(X))\n",
        "\n",
        "    # compute discrete firing times\n",
        "    tau_eff = 20e-3/time_step\n",
        "    firing_times = np.array(current2firing_time(X, tau=tau_eff, tmax=nb_steps), dtype=np.int)\n",
        "    unit_numbers = np.arange(nb_units)\n",
        "\n",
        "    if shuffle:\n",
        "        np.random.shuffle(sample_index)\n",
        "\n",
        "    total_batch_count = 0\n",
        "    counter = 0\n",
        "    while counter<number_of_batches:\n",
        "        batch_index = sample_index[batch_size*counter:batch_size*(counter+1)]\n",
        "\n",
        "        coo = [ [] for i in range(3)]\n",
        "        for bc,idx in enumerate(batch_index):\n",
        "            c = firing_times[idx]<nb_steps\n",
        "            times, units = firing_times[idx][c], unit_numbers[c]\n",
        "\n",
        "            batch = [bc for _ in range(len(times))]\n",
        "            coo[0].extend(batch)\n",
        "            coo[1].extend(times)\n",
        "            coo[2].entend(units)\n",
        "\n",
        "        i = torch.LongTensor(coo).to(device)\n",
        "        v = torch.FloatTensor(np.ones(len(coo[0]))).to(device)\n",
        "\n",
        "        X_batch = torch.sparse.FloatTensor(i, v, torch.Size([batch_size, nb_steps, nb_units])).to(device)\n",
        "        y_batch = torch.tensor(labels_[batch_index],device=device)\n",
        "\n",
        "        yield X_batch.to(device=device), y_batch.to(device=device)\n",
        "\n",
        "        counter += 1"
      ],
      "metadata": {
        "id": "9U4Cr1PPUNMA"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tau_mem = 10e-3\n",
        "tau_syn = 5e-3\n",
        "\n",
        "alpha = float(np.exp(-time_step/tau_syn))\n",
        "beta = float(np.exp(-time_step/tau_mem))\n",
        "\n",
        "weight_scale = 7*(1.0-beta) # this should give us some spikes to begin with\n",
        "\n",
        "w1 = torch.empty((nb_inputs, nb_hidden), device=device, dtype=dtype, requires_grad=True)\n",
        "torch.nn.init.normal_(w1, mean=0.0, std=weight_scale/np.sqrt(nb_inputs))"
      ],
      "metadata": {
        "id": "8TrrMUBIlrO9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}